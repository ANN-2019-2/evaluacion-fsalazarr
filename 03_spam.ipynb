{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-spam.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n3lnWjvI83ix",
        "colab": {}
      },
      "source": [
        "# Filtado de mensajes spam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkW2bHKNYLhB",
        "colab_type": "text"
      },
      "source": [
        "## Descripción del problema real"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO8zqeQFYMXW",
        "colab_type": "text"
      },
      "source": [
        "La recepción de publicidad no deseada a traves mensajes de texto usando SMS (Short Message Service) es un problema que afecta a muchos usuarios de teléfonos móviles. El problema radica en que los usuarios deben pagar por los mesajes recibidos, y por este motivo resulta muy importante que las compañías prestadoras del servicio puedan filtrar mensajes indeseados antes de enviarlos a su destinatario final. Los mensajes tienen una longitud máxima de 160 caracteres, por lo que el texto resulta poco para realizar la clasificación, en comparación con textos más largos (como los emails). Adicionalmente, los errores de digitación dificultan el proceso de detección automática."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ghf-oAvdYMab",
        "colab_type": "text"
      },
      "source": [
        "## Descripción del problema en términos de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8kxTa6hYMan",
        "colab_type": "text"
      },
      "source": [
        "Se tiene una muestra contiene 5574 mensajes en inglés, no codificados y clasificados como legítimos (ham) o spam (http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/). La información está almacenada en el archivo `datos/spam-sms.zip`.El problema en términos de los datos consiste en clasificar si un mensaje SMS es legítico o spam, a partir del análisis de las palabras que contiente, partiendo del supuesto de que ciertas palabras que son más frecuentes dependiendo del tipo de mensaje. Esto implica que en la fase de preparación de los datos se deben extraer las palabras que contiene cada mensaje para poder realizar el análsis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2RBqqabYMaz",
        "colab_type": "text"
      },
      "source": [
        "## Aproximaciones posibles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyeYIKLfYMbC",
        "colab_type": "text"
      },
      "source": [
        "En este caso, se desea comparar los resultados de un modelo de redes neuronales artificiales y otras técnicas estadísticas para realizar la clasificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNvQzW4QYMbO",
        "colab_type": "text"
      },
      "source": [
        "## Requerimientos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqSzof6fYMgr",
        "colab_type": "text"
      },
      "source": [
        "Usted debe:\n",
        "\n",
        "* Preprocesar los datos para representarlos usando bag-of-words.\n",
        "\n",
        "\n",
        "* Construir un modelo de regresión logística como punto base para la comparación con otros modelos más complejos.\n",
        "\n",
        "\n",
        "* Construir un modelo de redes neuronales artificiales. Asimismo, debe determinar el número de neuronas en la capa o capas ocultas.\n",
        "\n",
        "\n",
        "* Utiizar una técnica como crossvalidation u otra similar para establecer la robustez del modelo.\n",
        "\n",
        "\n",
        "* Presentar métricas de desempeño para establecer las bondades y falencias de cada clasificador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIyaD8IqYx6r",
        "colab_type": "code",
        "outputId": "bccbd0c8-bb87-45f7-85d9-99b7f622975d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "##En orden de ejecutar el trabajo, es indispensable que la carpeta \"Redes Neuronales y Algoritmos Bioinspirados - Trabajo Final\",\n",
        "##que se adjunta con éste archivo, debe ser agregada a \"Mi Unidad\" en su propio drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxlOF6Click-",
        "colab_type": "code",
        "outputId": "80fd4671-5674-41c3-93a9-adfd51490e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import glob\n",
        "import re"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5bku2tvi-Cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Redes Neuronales y Algoritmos Bioinspirados - Trabajo Final/datos/SMSSpamCollection.txt',delimiter='\\t',names=['type','text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAdJdqmQvn5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"type\"].replace({\"ham\": \"0\", \"spam\": \"1\"}, inplace=True)\n",
        "x = df['text']\n",
        "y = df['type']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7rHVuwli9cN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Procesamiento del lenguaje neutral\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def cleanText(message):   \n",
        "   \n",
        "    message = message.translate(str.maketrans('', '', string.punctuation))\n",
        "    words = [stemmer.stem(word) for word in message.split() if word.lower() not in stopwords.words(\"english\")]\n",
        "    return \" \".join(words)\n",
        "    \n",
        "X = list(map(cleanText, x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiLjo5qki9KW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Bag of words\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1CmFtbii86t",
        "colab_type": "code",
        "outputId": "803637e7-4301-44c2-c378-a9511aa16836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 8098)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UmboAewi8lI",
        "colab_type": "code",
        "outputId": "2d4d98ef-7d49-4f73-9223-e82e52404c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X = X.toarray()\n",
        "\n",
        "X[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4VGYnr8i8Id",
        "colab_type": "code",
        "outputId": "9fa784ea-830e-4b55-9e1c-eaf7dbb171e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "##Modelo (Regresión Logistica)\n",
        "y=y.astype('int')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , stratify = y, test_size = 0.3,random_state=101)\n",
        "clf = LogisticRegression(solver='lbfgs')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1443,    5],\n",
              "       [  31,  193]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFyws6oZxPw7",
        "colab_type": "code",
        "outputId": "6a8bdafb-0c7d-4d35-d97a-5c3c0e425382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9784688995215312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osnm6oK2xiqr",
        "colab_type": "code",
        "outputId": "fc451461-4127-4613-885a-11f881f54b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1448\n",
            "           1       0.97      0.86      0.91       224\n",
            "\n",
            "    accuracy                           0.98      1672\n",
            "   macro avg       0.98      0.93      0.95      1672\n",
            "weighted avg       0.98      0.98      0.98      1672\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bR9poFxxlmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Clasificador con redes neuronales\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0LV0RKZ0Gpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2MMf_ztxv74",
        "colab_type": "code",
        "outputId": "d077b1f0-2d2a-471d-987f-a3e9cb59a4e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def grid_layers(capas):\n",
        "    param = []\n",
        "\n",
        "    for i in range(len(capas)):\n",
        "\n",
        "        classifier = tf.keras.Sequential()\n",
        "\n",
        "        classifier.add(layers.Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu', input_dim = 8098))\n",
        "\n",
        "        for j in range(capas[i]-1):\n",
        "\n",
        "            classifier.add(layers.Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "        classifier.add(layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "        classifier.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "        classifier.fit(X_train, y_train, batch_size = 50, epochs = 30)\n",
        "\n",
        "        y_pred = classifier.predict(X_test)\n",
        "\n",
        "        y_pred = (y_pred > 0.5)\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        param.append([classifier.summary(),cm,classifier.evaluate(X_test, y_test)])\n",
        "\n",
        "    return param\n",
        "\n",
        "layersx = [2,5,8]\n",
        "\n",
        "resultado = grid_layers(layersx)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8641\n",
            "Epoch 2/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.1291 - accuracy: 0.9026\n",
            "Epoch 3/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9962\n",
            "Epoch 4/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9990\n",
            "Epoch 5/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9997\n",
            "Epoch 6/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 5)                 40495     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 40,531\n",
            "Trainable params: 40,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9862\n",
            "Epoch 1/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8659\n",
            "Epoch 2/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.9359\n",
            "Epoch 3/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9962\n",
            "Epoch 4/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.9992\n",
            "Epoch 5/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.9992\n",
            "Epoch 6/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.9992\n",
            "Epoch 7/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 8/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 9/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 10/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 11/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 12/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 13/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 14/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 15/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 16/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 17/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 18/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 19/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 20/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 21/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 22/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 23/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 24/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 25/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 26/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 27/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 28/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 29/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 30/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 5)                 40495     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 40,621\n",
            "Trainable params: 40,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9844\n",
            "Epoch 1/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.8659\n",
            "Epoch 2/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.2031 - accuracy: 0.8659\n",
            "Epoch 3/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.1155 - accuracy: 0.9367\n",
            "Epoch 4/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9962\n",
            "Epoch 5/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9982\n",
            "Epoch 6/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9990\n",
            "Epoch 8/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9995\n",
            "Epoch 9/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0226 - accuracy: 0.9995\n",
            "Epoch 10/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9995\n",
            "Epoch 11/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9995\n",
            "Epoch 12/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9995\n",
            "Epoch 13/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9995\n",
            "Epoch 14/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9995\n",
            "Epoch 15/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9995\n",
            "Epoch 16/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0093 - accuracy: 0.9995\n",
            "Epoch 17/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9995\n",
            "Epoch 18/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9995\n",
            "Epoch 19/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9995\n",
            "Epoch 20/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9995\n",
            "Epoch 21/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9995\n",
            "Epoch 22/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9995\n",
            "Epoch 23/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 0.9995\n",
            "Epoch 24/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.9995\n",
            "Epoch 25/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9995\n",
            "Epoch 26/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9995\n",
            "Epoch 27/30\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9995\n",
            "Epoch 28/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.9995\n",
            "Epoch 29/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.9995\n",
            "Epoch 30/30\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9995\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 5)                 40495     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 40,711\n",
            "Trainable params: 40,711\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.9821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZj2vzHnBKva",
        "colab_type": "code",
        "outputId": "aafb4542-9b59-45b4-dfd2-4e27b0f5ea2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "resultado"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[None, array([[1448,    0],\n",
              "         [  23,  201]]), [0.12936080992221832, 0.9862440228462219]],\n",
              " [None, array([[1448,    0],\n",
              "         [  26,  198]]), [0.21874511241912842, 0.9844497442245483]],\n",
              " [None, array([[1444,    4],\n",
              "         [  26,  198]]), [0.3445158302783966, 0.9820573925971985]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMCAOWZmBdjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precision = [i[2][1] for i in resultado]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv6HjrKVBuFz",
        "colab_type": "code",
        "outputId": "9cbe5c19-f48b-485f-8df7-82d61a80472b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.bar([\"2 Capas\",\"5 Capas\",\"8 Capas\"],precision)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdA93J3fCCl1",
        "colab_type": "code",
        "outputId": "18a52a47-e98f-4fc1-94ef-0ccf0307b64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def grid_neurons(neuronas):\n",
        "\n",
        "    param = []\n",
        "  \n",
        "    for i in range(len(neuronas)):\n",
        "    \n",
        "        classifier = tf.keras.Sequential()\n",
        "\n",
        "        classifier.add(layers.Dense(units = neuronas[i], kernel_initializer = 'uniform', activation = 'relu', input_dim = 8098))\n",
        "\n",
        "        classifier.add(layers.Dense(units = neuronas[i], kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "        classifier.add(layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "        classifier.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "        classifier.fit(X_train, y_train, batch_size = 32, epochs = 30)\n",
        "\n",
        "        y_pred = classifier.predict(X_test)\n",
        "\n",
        "        y_pred = (y_pred > 0.5)\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        param.append([classifier.summary(),cm,classifier.evaluate(X_test, y_test)])\n",
        "\n",
        "    return param\n",
        "\n",
        "neurons = [8,16,32,64]\n",
        "\n",
        "resultado_neuronas = grid_neurons(neurons)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 0.2774 - accuracy: 0.8590\n",
            "Epoch 2/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.9726\n",
            "Epoch 3/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0583 - accuracy: 0.9967\n",
            "Epoch 4/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9992\n",
            "Epoch 5/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9995\n",
            "Epoch 6/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9997\n",
            "Epoch 7/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 8/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2596e-04 - accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 1.2852e-04 - accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 8.2850e-05 - accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.4516e-05 - accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.2251e-05 - accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3179e-05 - accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.6311e-05 - accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.0925e-05 - accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 2.6450e-05 - accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 2.3256e-05 - accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 2.0035e-05 - accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 1.7612e-05 - accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 1.5471e-05 - accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 1.3705e-05 - accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 1.2201e-05 - accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 1.0843e-05 - accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 9.8038e-06 - accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 8.7267e-06 - accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 7.9096e-06 - accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 7.0991e-06 - accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.4485e-06 - accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8346e-06 - accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.3092e-06 - accuracy: 1.0000\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 8)                 64792     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 64,873\n",
            "Trainable params: 64,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9892\n",
            "Epoch 1/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.2440 - accuracy: 0.8885\n",
            "Epoch 2/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0830 - accuracy: 0.9921\n",
            "Epoch 3/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9995\n",
            "Epoch 5/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9997\n",
            "Epoch 6/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 9.5505e-04 - accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 8.7181e-04 - accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 7.9846e-04 - accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 7.3305e-04 - accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 6.7319e-04 - accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 6.1966e-04 - accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 5.7147e-04 - accuracy: 1.0000\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 16)                129584    \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 129,873\n",
            "Trainable params: 129,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9874\n",
            "Epoch 1/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.2275 - accuracy: 0.8987\n",
            "Epoch 2/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0792 - accuracy: 0.9921\n",
            "Epoch 3/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0443 - accuracy: 0.9977\n",
            "Epoch 4/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9990\n",
            "Epoch 5/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0200 - accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0143 - accuracy: 0.9995\n",
            "Epoch 7/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.9995\n",
            "Epoch 8/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9995\n",
            "Epoch 9/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9995\n",
            "Epoch 10/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9995\n",
            "Epoch 11/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9995\n",
            "Epoch 12/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9995\n",
            "Epoch 13/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9995\n",
            "Epoch 14/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 0.9995\n",
            "Epoch 15/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9995\n",
            "Epoch 16/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9995\n",
            "Epoch 17/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9995\n",
            "Epoch 18/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9995\n",
            "Epoch 19/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9995\n",
            "Epoch 20/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9995\n",
            "Epoch 21/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 0.9995\n",
            "Epoch 22/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9995\n",
            "Epoch 23/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9995\n",
            "Epoch 24/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9995\n",
            "Epoch 25/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9995\n",
            "Epoch 26/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 27/30\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 28/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 29/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9992\n",
            "Epoch 30/30\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9982\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_24 (Dense)             (None, 32)                259168    \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 260,257\n",
            "Trainable params: 260,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.1409 - accuracy: 0.9797\n",
            "Epoch 1/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 0.2109 - accuracy: 0.9244\n",
            "Epoch 2/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 0.0266 - accuracy: 0.9923\n",
            "Epoch 3/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 4/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 2.6367e-04 - accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 1.1315e-04 - accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 6.9947e-05 - accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 4.8529e-05 - accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 3.5430e-05 - accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 2.7121e-05 - accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 2.1420e-05 - accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 1.7173e-05 - accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 1.4231e-05 - accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 1.1683e-05 - accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 9.8310e-06 - accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 8.3660e-06 - accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 7.1931e-06 - accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 6.2042e-06 - accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 5.4236e-06 - accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 4.7313e-06 - accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 4.1637e-06 - accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 3.6821e-06 - accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 3.2735e-06 - accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 2.9161e-06 - accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 2.6071e-06 - accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 2.3462e-06 - accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 2.1151e-06 - accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 1.8982e-06 - accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 1.7168e-06 - accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 1.5542e-06 - accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 1.4124e-06 - accuracy: 1.0000\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_27 (Dense)             (None, 64)                518336    \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 522,561\n",
            "Trainable params: 522,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GO6KqUeCsdB",
        "colab_type": "code",
        "outputId": "9ca7f9cd-8e6a-46cb-eef2-84c067a99804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "resultado_neuronas"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[None, array([[1446,    2],\n",
              "         [  16,  208]]), [0.1299692690372467, 0.989234447479248]],\n",
              " [None, array([[1445,    3],\n",
              "         [  18,  206]]), [0.1541954129934311, 0.9874401688575745]],\n",
              " [None, array([[1428,   20],\n",
              "         [  14,  210]]), [0.140886127948761, 0.9796651005744934]],\n",
              " [None, array([[1447,    1],\n",
              "         [  21,  203]]), [0.16790522634983063, 0.9868420958518982]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aElWyQEC3EK",
        "colab_type": "code",
        "outputId": "fb708f81-202d-484f-ea79-33ee320162ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "def regresor_base(optimizer,activation):\n",
        "    modelo = tf.keras.Sequential()\n",
        "    modelo.add(layers.Dense(units = 8, kernel_initializer = 'uniform', activation = activation, input_dim = 8098))\n",
        "    modelo.add(layers.Dropout(rate = 0.1))\n",
        "    modelo.add(layers.Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
        "    modelo.add(layers.Dropout(rate = 0.1))\n",
        "    modelo.add(layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    \n",
        "    modelo.compile(optimizer = optimizer, loss = 'binary_crossentropy' ,metrics = ['acc'])\n",
        "    \n",
        "    return  modelo\n",
        "\n",
        "\n",
        "regresor = KerasClassifier(build_fn = regresor_base)\n",
        "\n",
        "parameters = {'batch_size': [5,10],\n",
        "              'epochs': [20,40],\n",
        "              'optimizer': [tf.keras.optimizers.Adam(0.01)],\n",
        "              'activation':['sigmoid','relu']              \n",
        "             }\n",
        "\n",
        "## Cross validation \n",
        "grid_search = GridSearchCV(estimator = regresor,\n",
        "                           param_grid = parameters,\n",
        "                           cv=2\n",
        "                           )\n",
        "grid_search = grid_search.fit(X_train, y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.3259 - acc: 0.8621\n",
            "Epoch 2/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.1216 - acc: 0.9492\n",
            "Epoch 3/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0498 - acc: 0.9949\n",
            "Epoch 4/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0244 - acc: 0.9995\n",
            "Epoch 5/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0173 - acc: 0.9995\n",
            "Epoch 6/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0133 - acc: 0.9995\n",
            "Epoch 7/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0100 - acc: 0.9995\n",
            "Epoch 8/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0097 - acc: 0.9995\n",
            "Epoch 9/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 0.9990\n",
            "Epoch 10/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0085 - acc: 0.9995\n",
            "Epoch 11/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0085 - acc: 0.9995\n",
            "Epoch 12/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0079 - acc: 0.9995\n",
            "Epoch 13/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0090 - acc: 0.9990\n",
            "Epoch 14/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0076 - acc: 0.9995\n",
            "Epoch 15/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0065 - acc: 0.9995\n",
            "Epoch 16/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0077 - acc: 0.9995\n",
            "Epoch 17/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0062 - acc: 0.9995\n",
            "Epoch 18/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 19/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 8.3736e-04 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 9.8041e-04 - acc: 1.0000\n",
            "390/390 [==============================] - 0s 1ms/step - loss: 0.2521 - acc: 0.9738\n",
            "Epoch 1/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.3191 - acc: 0.8667\n",
            "Epoch 2/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.1223 - acc: 0.9544\n",
            "Epoch 3/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0461 - acc: 0.9964\n",
            "Epoch 4/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0204 - acc: 0.9995\n",
            "Epoch 5/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0119 - acc: 1.0000\n",
            "Epoch 6/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0079 - acc: 1.0000\n",
            "Epoch 7/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 1.0000\n",
            "Epoch 8/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0040 - acc: 1.0000\n",
            "Epoch 9/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 10/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 11/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 12/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 13/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 14/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 9.0705e-04 - acc: 1.0000\n",
            "Epoch 15/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 7.0632e-04 - acc: 1.0000\n",
            "Epoch 16/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 6.4769e-04 - acc: 1.0000\n",
            "Epoch 17/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 4.6900e-04 - acc: 1.0000\n",
            "Epoch 18/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.8752e-04 - acc: 1.0000\n",
            "Epoch 19/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 4.2333e-04 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.9478e-04 - acc: 1.0000\n",
            "390/390 [==============================] - 1s 1ms/step - loss: 0.1830 - acc: 0.9800\n",
            "Epoch 1/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.3212 - acc: 0.8626\n",
            "Epoch 2/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.1175 - acc: 0.9538\n",
            "Epoch 3/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0464 - acc: 0.9949\n",
            "Epoch 4/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0238 - acc: 0.9979\n",
            "Epoch 5/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0158 - acc: 0.9995\n",
            "Epoch 6/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0111 - acc: 0.9995\n",
            "Epoch 7/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.9995\n",
            "Epoch 8/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0098 - acc: 0.9995\n",
            "Epoch 9/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0091 - acc: 0.9995\n",
            "Epoch 10/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0075 - acc: 0.9995\n",
            "Epoch 11/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 0.9995\n",
            "Epoch 12/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0079 - acc: 0.9995\n",
            "Epoch 13/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0077 - acc: 0.9995\n",
            "Epoch 14/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0063 - acc: 0.9995\n",
            "Epoch 15/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 16/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 17/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 18/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 8.3281e-04 - acc: 1.0000\n",
            "Epoch 19/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 7.2482e-04 - acc: 1.0000\n",
            "Epoch 20/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 5.7251e-04 - acc: 1.0000\n",
            "Epoch 21/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 4.9631e-04 - acc: 1.0000\n",
            "Epoch 22/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.4766e-04 - acc: 1.0000\n",
            "Epoch 23/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 4.5334e-04 - acc: 1.0000\n",
            "Epoch 24/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.5237e-04 - acc: 1.0000\n",
            "Epoch 25/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.6146e-04 - acc: 1.0000\n",
            "Epoch 26/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.2157e-04 - acc: 1.0000\n",
            "Epoch 27/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.0242e-04 - acc: 1.0000\n",
            "Epoch 28/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.9048e-04 - acc: 1.0000\n",
            "Epoch 29/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.2292e-04 - acc: 1.0000\n",
            "Epoch 30/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.2151e-04 - acc: 1.0000\n",
            "Epoch 31/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 8.0948e-05 - acc: 1.0000\n",
            "Epoch 32/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 6.4821e-05 - acc: 1.0000\n",
            "Epoch 33/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 5.4169e-05 - acc: 1.0000\n",
            "Epoch 34/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 5.0295e-05 - acc: 1.0000\n",
            "Epoch 35/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 9.6688e-05 - acc: 1.0000\n",
            "Epoch 36/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.9075e-04 - acc: 1.0000\n",
            "Epoch 37/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 6.8183e-05 - acc: 1.0000\n",
            "Epoch 38/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 4.0682e-05 - acc: 1.0000\n",
            "Epoch 39/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 5.0566e-05 - acc: 1.0000\n",
            "Epoch 40/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.9951e-05 - acc: 1.0000\n",
            "390/390 [==============================] - 0s 1ms/step - loss: 0.4368 - acc: 0.9738\n",
            "Epoch 1/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.3274 - acc: 0.8621\n",
            "Epoch 2/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.1273 - acc: 0.9508\n",
            "Epoch 3/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0461 - acc: 0.9964\n",
            "Epoch 4/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0203 - acc: 0.9995\n",
            "Epoch 5/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0123 - acc: 0.9995\n",
            "Epoch 6/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0077 - acc: 1.0000\n",
            "Epoch 7/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 8/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 9/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 10/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 11/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 12/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 13/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 14/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 9.2049e-04 - acc: 1.0000\n",
            "Epoch 15/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 9.5374e-04 - acc: 1.0000\n",
            "Epoch 16/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 8.2596e-04 - acc: 1.0000\n",
            "Epoch 17/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 6.8681e-04 - acc: 1.0000\n",
            "Epoch 18/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 4.0761e-04 - acc: 1.0000\n",
            "Epoch 19/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.9181e-04 - acc: 1.0000\n",
            "Epoch 20/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.6742e-04 - acc: 1.0000\n",
            "Epoch 21/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.1978e-04 - acc: 1.0000\n",
            "Epoch 22/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.8663e-04 - acc: 1.0000\n",
            "Epoch 23/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.7504e-04 - acc: 1.0000\n",
            "Epoch 24/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.4982e-04 - acc: 1.0000\n",
            "Epoch 25/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.0460e-04 - acc: 1.0000\n",
            "Epoch 26/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 9.5039e-05 - acc: 1.0000\n",
            "Epoch 27/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.1754e-04 - acc: 1.0000\n",
            "Epoch 28/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 0.9995\n",
            "Epoch 29/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 8.8511e-05 - acc: 1.0000\n",
            "Epoch 30/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.0710e-04 - acc: 1.0000\n",
            "Epoch 31/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 7.5961e-05 - acc: 1.0000\n",
            "Epoch 32/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 7.7539e-05 - acc: 1.0000\n",
            "Epoch 33/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 6.1952e-05 - acc: 1.0000\n",
            "Epoch 34/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 6.4914e-05 - acc: 1.0000\n",
            "Epoch 35/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 5.9382e-05 - acc: 1.0000\n",
            "Epoch 36/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 5.0383e-05 - acc: 1.0000\n",
            "Epoch 37/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 6.4111e-05 - acc: 1.0000\n",
            "Epoch 38/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 4.6261e-05 - acc: 1.0000\n",
            "Epoch 39/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.1620e-05 - acc: 1.0000\n",
            "Epoch 40/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.6472e-05 - acc: 1.0000\n",
            "390/390 [==============================] - 1s 1ms/step - loss: 0.2656 - acc: 0.9805\n",
            "Epoch 1/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.3498 - acc: 0.8651\n",
            "Epoch 2/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.1767 - acc: 0.8969\n",
            "Epoch 3/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0810 - acc: 0.9928\n",
            "Epoch 4/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0421 - acc: 0.9985\n",
            "Epoch 5/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0275 - acc: 0.9990\n",
            "Epoch 6/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0187 - acc: 0.9995\n",
            "Epoch 7/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0151 - acc: 0.9995\n",
            "Epoch 8/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0133 - acc: 0.9995\n",
            "Epoch 9/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0122 - acc: 0.9990\n",
            "Epoch 10/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0098 - acc: 0.9995\n",
            "Epoch 11/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0052 - acc: 1.0000\n",
            "Epoch 12/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0044 - acc: 0.9995\n",
            "Epoch 13/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 14/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0030 - acc: 1.0000\n",
            "Epoch 15/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 16/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 17/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 18/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 19/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0018 - acc: 0.9995\n",
            "195/195 [==============================] - 0s 1ms/step - loss: 0.2191 - acc: 0.9738\n",
            "Epoch 1/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.3550 - acc: 0.8667\n",
            "Epoch 2/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.1876 - acc: 0.8815\n",
            "Epoch 3/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0833 - acc: 0.9913\n",
            "Epoch 4/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0399 - acc: 0.9995\n",
            "Epoch 5/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0250 - acc: 0.9995\n",
            "Epoch 6/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0166 - acc: 1.0000\n",
            "Epoch 7/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0118 - acc: 1.0000\n",
            "Epoch 8/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0090 - acc: 1.0000\n",
            "Epoch 9/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0078 - acc: 0.9995\n",
            "Epoch 10/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0059 - acc: 1.0000\n",
            "Epoch 11/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0056 - acc: 0.9990\n",
            "Epoch 12/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0040 - acc: 1.0000\n",
            "Epoch 13/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0036 - acc: 1.0000\n",
            "Epoch 14/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 15/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 16/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 17/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 18/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0021 - acc: 0.9995\n",
            "Epoch 19/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
            "195/195 [==============================] - 0s 1ms/step - loss: 0.1326 - acc: 0.9810\n",
            "Epoch 1/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.3659 - acc: 0.8610\n",
            "Epoch 2/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.1976 - acc: 0.8672\n",
            "Epoch 3/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0934 - acc: 0.9877\n",
            "Epoch 4/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0500 - acc: 0.9979\n",
            "Epoch 5/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0318 - acc: 0.9995\n",
            "Epoch 6/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0221 - acc: 0.9990\n",
            "Epoch 7/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0172 - acc: 0.9995\n",
            "Epoch 8/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0137 - acc: 0.9995\n",
            "Epoch 9/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0140 - acc: 0.9990\n",
            "Epoch 10/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0108 - acc: 0.9990\n",
            "Epoch 11/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0097 - acc: 0.9995\n",
            "Epoch 12/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0083 - acc: 0.9995\n",
            "Epoch 13/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0093 - acc: 0.9995\n",
            "Epoch 14/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0081 - acc: 0.9995\n",
            "Epoch 15/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0094 - acc: 0.9995\n",
            "Epoch 16/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0083 - acc: 0.9995\n",
            "Epoch 17/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0080 - acc: 0.9995\n",
            "Epoch 18/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0052 - acc: 0.9995\n",
            "Epoch 19/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0071 - acc: 0.9995\n",
            "Epoch 20/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0071 - acc: 0.9995\n",
            "Epoch 21/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0081 - acc: 0.9990\n",
            "Epoch 22/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0055 - acc: 0.9995\n",
            "Epoch 23/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0065 - acc: 0.9995\n",
            "Epoch 24/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0064 - acc: 0.9990\n",
            "Epoch 25/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0067 - acc: 0.9995\n",
            "Epoch 26/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 27/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 28/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0026 - acc: 0.9995\n",
            "Epoch 29/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 9.3747e-04 - acc: 1.0000\n",
            "Epoch 30/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 8.2610e-04 - acc: 1.0000\n",
            "Epoch 31/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 8.1883e-04 - acc: 1.0000\n",
            "Epoch 32/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 6.8876e-04 - acc: 1.0000\n",
            "Epoch 33/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0011 - acc: 0.9995\n",
            "Epoch 34/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 6.0971e-04 - acc: 1.0000\n",
            "Epoch 35/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 4.8534e-04 - acc: 1.0000\n",
            "Epoch 36/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 4.4299e-04 - acc: 1.0000\n",
            "Epoch 37/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 7.0979e-04 - acc: 1.0000\n",
            "Epoch 38/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 3.9505e-04 - acc: 1.0000\n",
            "Epoch 39/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 3.1667e-04 - acc: 1.0000\n",
            "Epoch 40/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 8.5511e-04 - acc: 0.9995\n",
            "195/195 [==============================] - 0s 1ms/step - loss: 0.3124 - acc: 0.9728\n",
            "Epoch 1/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.3590 - acc: 0.8662\n",
            "Epoch 2/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.1943 - acc: 0.8749\n",
            "Epoch 3/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0906 - acc: 0.9903\n",
            "Epoch 4/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0445 - acc: 0.9979\n",
            "Epoch 5/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0266 - acc: 0.9990\n",
            "Epoch 6/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0180 - acc: 0.9995\n",
            "Epoch 7/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0124 - acc: 1.0000\n",
            "Epoch 8/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0094 - acc: 1.0000\n",
            "Epoch 9/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0076 - acc: 1.0000\n",
            "Epoch 10/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0059 - acc: 1.0000\n",
            "Epoch 11/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0053 - acc: 1.0000\n",
            "Epoch 12/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0043 - acc: 1.0000\n",
            "Epoch 13/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 14/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 15/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 16/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 17/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 18/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 19/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0020 - acc: 0.9995\n",
            "Epoch 20/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 21/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 22/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 23/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 9.3642e-04 - acc: 1.0000\n",
            "Epoch 24/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 9.1912e-04 - acc: 1.0000\n",
            "Epoch 25/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 8.2505e-04 - acc: 1.0000\n",
            "Epoch 26/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 7.2758e-04 - acc: 1.0000\n",
            "Epoch 27/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 7.1289e-04 - acc: 1.0000\n",
            "Epoch 28/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 5.4416e-04 - acc: 1.0000\n",
            "Epoch 29/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 6.2787e-04 - acc: 1.0000\n",
            "Epoch 30/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 5.1893e-04 - acc: 1.0000\n",
            "Epoch 31/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 5.2933e-04 - acc: 1.0000\n",
            "Epoch 32/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 3.8135e-04 - acc: 1.0000\n",
            "Epoch 33/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 4.3431e-04 - acc: 1.0000\n",
            "Epoch 34/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 6.6332e-04 - acc: 1.0000\n",
            "Epoch 35/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0011 - acc: 0.9995\n",
            "Epoch 36/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 3.1092e-04 - acc: 1.0000\n",
            "Epoch 37/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 3.0166e-04 - acc: 1.0000\n",
            "Epoch 38/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 2.4206e-04 - acc: 1.0000\n",
            "Epoch 39/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 2.5692e-04 - acc: 1.0000\n",
            "Epoch 40/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 1.9448e-04 - acc: 1.0000\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.2353 - acc: 0.9805\n",
            "Epoch 1/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.2471 - acc: 0.8903\n",
            "Epoch 2/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0918 - acc: 0.9785\n",
            "Epoch 3/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0562 - acc: 0.9851\n",
            "Epoch 4/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0501 - acc: 0.9841\n",
            "Epoch 5/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0348 - acc: 0.9918\n",
            "Epoch 6/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0386 - acc: 0.9892\n",
            "Epoch 7/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0296 - acc: 0.9928\n",
            "Epoch 8/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0405 - acc: 0.9887\n",
            "Epoch 9/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0310 - acc: 0.9918\n",
            "Epoch 10/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0258 - acc: 0.9938\n",
            "Epoch 11/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0514 - acc: 0.9846\n",
            "Epoch 12/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0232 - acc: 0.9949\n",
            "Epoch 13/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0287 - acc: 0.9928\n",
            "Epoch 14/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0378 - acc: 0.9897\n",
            "Epoch 15/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0401 - acc: 0.9887\n",
            "Epoch 16/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0413 - acc: 0.9882\n",
            "Epoch 17/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0309 - acc: 0.9918\n",
            "Epoch 18/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0335 - acc: 0.9908\n",
            "Epoch 19/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0330 - acc: 0.9913\n",
            "Epoch 20/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0301 - acc: 0.9923\n",
            "390/390 [==============================] - 1s 1ms/step - loss: 0.6491 - acc: 0.9687\n",
            "Epoch 1/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.2675 - acc: 0.9026\n",
            "Epoch 2/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0797 - acc: 0.9862\n",
            "Epoch 3/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0330 - acc: 0.9964\n",
            "Epoch 4/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0198 - acc: 0.9974\n",
            "Epoch 5/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0132 - acc: 0.9979\n",
            "Epoch 6/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.9979\n",
            "Epoch 7/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0082 - acc: 0.9990\n",
            "Epoch 8/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0151 - acc: 0.9969\n",
            "Epoch 9/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0032 - acc: 1.0000\n",
            "Epoch 10/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0066 - acc: 0.9990\n",
            "Epoch 11/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0063 - acc: 0.9990\n",
            "Epoch 12/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 13/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 14/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0086 - acc: 0.9985\n",
            "Epoch 15/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0037 - acc: 0.9995\n",
            "Epoch 16/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0035 - acc: 0.9995\n",
            "Epoch 17/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0062 - acc: 0.9990\n",
            "Epoch 18/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0061 - acc: 0.9990\n",
            "Epoch 19/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0137 - acc: 0.9974\n",
            "Epoch 20/20\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0061 - acc: 0.9990\n",
            "390/390 [==============================] - 0s 1ms/step - loss: 0.6374 - acc: 0.9728\n",
            "Epoch 1/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.2479 - acc: 0.9026\n",
            "Epoch 2/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0802 - acc: 0.9841\n",
            "Epoch 3/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0292 - acc: 0.9969\n",
            "Epoch 4/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0136 - acc: 0.9995\n",
            "Epoch 5/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 6/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0074 - acc: 0.9995\n",
            "Epoch 7/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 8/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 9/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0027 - acc: 0.9995\n",
            "Epoch 10/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 11/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 12/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 0.9995\n",
            "Epoch 13/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0035 - acc: 0.9995\n",
            "Epoch 14/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 6.7504e-04 - acc: 1.0000\n",
            "Epoch 15/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 6.6296e-04 - acc: 1.0000\n",
            "Epoch 16/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 4.4634e-04 - acc: 1.0000\n",
            "Epoch 17/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.7046e-04 - acc: 1.0000\n",
            "Epoch 18/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.0777e-04 - acc: 1.0000\n",
            "Epoch 19/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.3479e-04 - acc: 1.0000\n",
            "Epoch 20/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.9042e-04 - acc: 1.0000\n",
            "Epoch 21/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.8014e-04 - acc: 1.0000\n",
            "Epoch 22/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.4096e-04 - acc: 1.0000\n",
            "Epoch 23/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.0791e-04 - acc: 1.0000\n",
            "Epoch 24/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 9.4579e-05 - acc: 1.0000\n",
            "Epoch 25/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 8.0455e-05 - acc: 1.0000\n",
            "Epoch 26/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 7.8765e-05 - acc: 1.0000\n",
            "Epoch 27/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 4.8977e-05 - acc: 1.0000\n",
            "Epoch 28/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.9798e-05 - acc: 1.0000\n",
            "Epoch 29/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.2473e-05 - acc: 1.0000\n",
            "Epoch 30/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.8350e-05 - acc: 1.0000\n",
            "Epoch 31/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.1611e-05 - acc: 1.0000\n",
            "Epoch 32/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.7721e-05 - acc: 1.0000\n",
            "Epoch 33/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.9995\n",
            "Epoch 34/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.9995\n",
            "Epoch 35/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.6771e-05 - acc: 1.0000\n",
            "Epoch 36/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 4.3931e-05 - acc: 1.0000\n",
            "Epoch 37/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.6341e-05 - acc: 1.0000\n",
            "Epoch 38/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.6770e-05 - acc: 1.0000\n",
            "Epoch 39/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.9995\n",
            "Epoch 40/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 5.8698e-05 - acc: 1.0000\n",
            "390/390 [==============================] - 0s 1ms/step - loss: 1.7358 - acc: 0.9687\n",
            "Epoch 1/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.2377 - acc: 0.9092\n",
            "Epoch 2/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0698 - acc: 0.9872\n",
            "Epoch 3/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0276 - acc: 0.9964\n",
            "Epoch 4/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0139 - acc: 0.9990\n",
            "Epoch 5/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0074 - acc: 0.9995\n",
            "Epoch 6/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 1.0000\n",
            "Epoch 7/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0032 - acc: 1.0000\n",
            "Epoch 8/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 9/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0041 - acc: 0.9995\n",
            "Epoch 10/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 11/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 12/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 9.8906e-04 - acc: 1.0000\n",
            "Epoch 13/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0035 - acc: 0.9995\n",
            "Epoch 14/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 6.4680e-04 - acc: 1.0000\n",
            "Epoch 15/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 5.0541e-04 - acc: 1.0000\n",
            "Epoch 16/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 5.7248e-04 - acc: 1.0000\n",
            "Epoch 17/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 3.4075e-04 - acc: 1.0000\n",
            "Epoch 18/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 0.9995\n",
            "Epoch 19/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.2778e-04 - acc: 1.0000\n",
            "Epoch 20/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.0209e-04 - acc: 1.0000\n",
            "Epoch 21/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.0154e-04 - acc: 1.0000\n",
            "Epoch 22/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0036 - acc: 0.9995\n",
            "Epoch 23/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.7869e-04 - acc: 1.0000\n",
            "Epoch 24/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0036 - acc: 0.9995\n",
            "Epoch 25/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0036 - acc: 0.9995\n",
            "Epoch 26/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 2.0842e-04 - acc: 1.0000\n",
            "Epoch 27/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.8803e-04 - acc: 1.0000\n",
            "Epoch 28/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.9968e-04 - acc: 1.0000\n",
            "Epoch 29/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.4560e-04 - acc: 1.0000\n",
            "Epoch 30/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.2791e-04 - acc: 1.0000\n",
            "Epoch 31/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.1034e-04 - acc: 1.0000\n",
            "Epoch 32/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 9.5841e-05 - acc: 1.0000\n",
            "Epoch 33/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 8.2738e-05 - acc: 1.0000\n",
            "Epoch 34/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 7.0001e-05 - acc: 1.0000\n",
            "Epoch 35/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 1.2424e-04 - acc: 1.0000\n",
            "Epoch 36/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 0.0076 - acc: 0.9985\n",
            "Epoch 37/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 8.4656e-05 - acc: 1.0000\n",
            "Epoch 38/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 7.6688e-05 - acc: 1.0000\n",
            "Epoch 39/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 9.2582e-05 - acc: 1.0000\n",
            "Epoch 40/40\n",
            "390/390 [==============================] - 1s 2ms/step - loss: 6.6998e-05 - acc: 1.0000\n",
            "390/390 [==============================] - 0s 1ms/step - loss: 0.7818 - acc: 0.9779\n",
            "Epoch 1/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.2634 - acc: 0.8928\n",
            "Epoch 2/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0922 - acc: 0.9887\n",
            "Epoch 3/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0442 - acc: 0.9969\n",
            "Epoch 4/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0248 - acc: 0.9990\n",
            "Epoch 5/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0150 - acc: 1.0000\n",
            "Epoch 6/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0106 - acc: 1.0000\n",
            "Epoch 7/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0077 - acc: 1.0000\n",
            "Epoch 8/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0059 - acc: 1.0000\n",
            "Epoch 9/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0047 - acc: 1.0000\n",
            "Epoch 10/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0038 - acc: 1.0000\n",
            "Epoch 11/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 12/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 13/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 14/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 15/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 16/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 17/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 18/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 19/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 9.0570e-04 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 7.9506e-04 - acc: 1.0000\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.6143 - acc: 0.9641\n",
            "Epoch 1/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.2759 - acc: 0.8692\n",
            "Epoch 2/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.1001 - acc: 0.9790\n",
            "Epoch 3/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0480 - acc: 0.9959\n",
            "Epoch 4/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0282 - acc: 0.9979\n",
            "Epoch 5/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0194 - acc: 0.9985\n",
            "Epoch 6/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0154 - acc: 0.9985\n",
            "Epoch 7/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0143 - acc: 0.9979\n",
            "Epoch 8/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0103 - acc: 0.9990\n",
            "Epoch 9/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0106 - acc: 0.9990\n",
            "Epoch 10/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0062 - acc: 0.9995\n",
            "Epoch 11/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0038 - acc: 1.0000\n",
            "Epoch 12/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0052 - acc: 0.9995\n",
            "Epoch 13/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 14/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0045 - acc: 0.9995\n",
            "Epoch 15/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 16/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0040 - acc: 0.9995\n",
            "Epoch 17/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 18/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 19/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 9.6004e-04 - acc: 1.0000\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.3687 - acc: 0.9749\n",
            "Epoch 1/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.2715 - acc: 0.8728\n",
            "Epoch 2/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0920 - acc: 0.9903\n",
            "Epoch 3/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0470 - acc: 0.9959\n",
            "Epoch 4/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0284 - acc: 0.9979\n",
            "Epoch 5/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0195 - acc: 0.9990\n",
            "Epoch 6/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0134 - acc: 0.9995\n",
            "Epoch 7/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0094 - acc: 0.9995\n",
            "Epoch 8/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0087 - acc: 0.9995\n",
            "Epoch 9/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0056 - acc: 1.0000\n",
            "Epoch 10/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0047 - acc: 1.0000\n",
            "Epoch 11/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 12/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0037 - acc: 0.9995\n",
            "Epoch 13/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0068 - acc: 0.9990\n",
            "Epoch 14/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 15/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0024 - acc: 0.9995\n",
            "Epoch 16/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 17/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0038 - acc: 0.9995\n",
            "Epoch 18/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 19/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 20/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0023 - acc: 0.9995\n",
            "Epoch 21/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0026 - acc: 0.9990\n",
            "Epoch 22/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 8.1551e-04 - acc: 1.0000\n",
            "Epoch 23/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 0.9995\n",
            "Epoch 24/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 7.6508e-04 - acc: 1.0000\n",
            "Epoch 25/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 6.1285e-04 - acc: 1.0000\n",
            "Epoch 26/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 5.5921e-04 - acc: 1.0000\n",
            "Epoch 27/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 4.6172e-04 - acc: 1.0000\n",
            "Epoch 28/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0034 - acc: 0.9995\n",
            "Epoch 29/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 4.1502e-04 - acc: 1.0000\n",
            "Epoch 30/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 3.8091e-04 - acc: 1.0000\n",
            "Epoch 31/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 3.7629e-04 - acc: 1.0000\n",
            "Epoch 32/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 4.5580e-04 - acc: 1.0000\n",
            "Epoch 33/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0020 - acc: 0.9990\n",
            "Epoch 34/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 5.8250e-04 - acc: 1.0000\n",
            "Epoch 35/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 3.8401e-04 - acc: 1.0000\n",
            "Epoch 36/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 2.0741e-04 - acc: 1.0000\n",
            "Epoch 37/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 1.8884e-04 - acc: 1.0000\n",
            "Epoch 38/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 1.7276e-04 - acc: 1.0000\n",
            "Epoch 39/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 2.1488e-04 - acc: 1.0000\n",
            "Epoch 40/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0015 - acc: 0.9995\n",
            "195/195 [==============================] - 0s 1ms/step - loss: 1.6765 - acc: 0.9615\n",
            "Epoch 1/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.2746 - acc: 0.8682\n",
            "Epoch 2/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0991 - acc: 0.9836\n",
            "Epoch 3/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0489 - acc: 0.9959\n",
            "Epoch 4/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0282 - acc: 0.9990\n",
            "Epoch 5/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0200 - acc: 0.9990\n",
            "Epoch 6/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0136 - acc: 0.9995\n",
            "Epoch 7/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0107 - acc: 0.9995\n",
            "Epoch 8/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0148 - acc: 0.9974\n",
            "Epoch 9/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0097 - acc: 0.9990\n",
            "Epoch 10/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0084 - acc: 0.9990\n",
            "Epoch 11/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0080 - acc: 0.9990\n",
            "Epoch 12/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0074 - acc: 0.9990\n",
            "Epoch 13/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0091 - acc: 0.9985\n",
            "Epoch 14/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0048 - acc: 0.9995\n",
            "Epoch 15/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0044 - acc: 0.9995\n",
            "Epoch 16/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0087 - acc: 0.9985\n",
            "Epoch 17/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0107 - acc: 0.9979\n",
            "Epoch 18/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0063 - acc: 0.9990\n",
            "Epoch 19/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0063 - acc: 0.9990\n",
            "Epoch 20/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0062 - acc: 0.9990\n",
            "Epoch 21/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0062 - acc: 0.9990\n",
            "Epoch 22/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 23/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0036 - acc: 0.9995\n",
            "Epoch 24/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 25/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 0.9995\n",
            "Epoch 26/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0061 - acc: 0.9990\n",
            "Epoch 27/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 0.9995\n",
            "Epoch 28/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 0.9995\n",
            "Epoch 29/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0061 - acc: 0.9990\n",
            "Epoch 30/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 31/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0089 - acc: 0.9985\n",
            "Epoch 32/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 0.9995\n",
            "Epoch 33/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 0.9995\n",
            "Epoch 34/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0034 - acc: 0.9995\n",
            "Epoch 35/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0034 - acc: 0.9995\n",
            "Epoch 36/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0034 - acc: 0.9995\n",
            "Epoch 37/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 6.0934e-04 - acc: 1.0000\n",
            "Epoch 38/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0034 - acc: 0.9995\n",
            "Epoch 39/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.0062 - acc: 0.9990\n",
            "Epoch 40/40\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 5.5274e-04 - acc: 1.0000\n",
            "195/195 [==============================] - 0s 2ms/step - loss: 0.6902 - acc: 0.9687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ec4954dc377d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                            \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                            )\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 736\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     81\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f113b0c90f0>, as the constructor either does not set or modifies parameter optimizer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0UrRpXJY8HN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Se logra una precisión en el cross validation de 91%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T-yRiRUZGYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "4cabe26b-bfb3-44c7-f9b1-ff20317572cd"
      },
      "source": [
        "resultado_neuronas"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[None, array([[1446,    2],\n",
              "         [  16,  208]]), [0.1299692690372467, 0.989234447479248]],\n",
              " [None, array([[1445,    3],\n",
              "         [  18,  206]]), [0.1541954129934311, 0.9874401688575745]],\n",
              " [None, array([[1428,   20],\n",
              "         [  14,  210]]), [0.140886127948761, 0.9796651005744934]],\n",
              " [None, array([[1447,    1],\n",
              "         [  21,  203]]), [0.16790522634983063, 0.9868420958518982]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsfCX7cMZJUr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1e391d5-e9bb-4847-a279-34cd897c88e7"
      },
      "source": [
        "neurons"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8, 16, 32, 64]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMBntOPCatJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = [i[-1][0] for i in resultado_neuronas]\n",
        "precission = [i[-1][1] for i in resultado_neuronas]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhMgd0-ha4nM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7bcc1b01-03cb-4423-c808-ac316633eec7"
      },
      "source": [
        "plt.plot(neurons, loss , '.-')\n",
        "plt.grid()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTJSyAmCMMVHKCoAxxkSp/w9ejP19Gf5eFgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hozkJRLa8sy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "38e9d5f4-d134-4089-f1c7-291996c0dc68"
      },
      "source": [
        "plt.plot(neurons, precission , '.-')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f11437e1dd8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlIfSAlBKKQ+lBaCUUh7q/wP+ppce0irkmwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBxZU8iJbPKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afd1ffe3-5f35-4bdd-c62a-6f8c617f080b"
      },
      "source": [
        "## Modelo final con hyper parametros ajustados\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "classifier = tf.keras.Sequential()\n",
        "\n",
        "classifier.add(layers.Dense(units = 16, kernel_initializer = 'uniform', activation = 'sigmoid', input_dim = 8098))\n",
        "\n",
        "classifier.add(layers.Dense(units = 16, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "classifier.add(layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "classifier.compile(optimizer = tf.keras.optimizers.Adam(0.01), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=5, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=1)\n",
        "\n",
        "classifier.fit(X_train, y_train, batch_size = 5, epochs = 100)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.1955 - accuracy: 0.9213\n",
            "Epoch 2/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9933\n",
            "Epoch 3/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.0103 - accuracy: 0.9979\n",
            "Epoch 4/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.0047 - accuracy: 0.9995\n",
            "Epoch 5/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 0.9997\n",
            "Epoch 6/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.0029 - accuracy: 0.9997\n",
            "Epoch 7/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.0029 - accuracy: 0.9997\n",
            "Epoch 8/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.0029 - accuracy: 0.9997\n",
            "Epoch 9/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.0027 - accuracy: 0.9997\n",
            "Epoch 10/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.0028 - accuracy: 0.9997\n",
            "Epoch 11/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.0027 - accuracy: 0.9997\n",
            "Epoch 12/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 0.0038 - accuracy: 0.9992\n",
            "Epoch 13/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 9.2620e-04 - accuracy: 0.9997\n",
            "Epoch 14/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.0000e-04 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 4.7150e-05 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.4873e-05 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.6439e-05 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.9842e-05 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.4618e-05 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.0562e-05 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 7.5043e-06 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 5.2572e-06 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.6421e-06 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.5057e-06 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.7171e-06 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.1724e-06 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 7.9860e-07 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 5.4258e-07 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.6902e-07 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.5112e-07 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.7096e-07 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.1638e-07 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 7.9509e-08 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 5.4474e-08 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.7406e-08 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.6027e-08 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.8143e-08 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.3279e-08 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 9.2222e-09 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 6.3996e-09 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 5.5418e-09 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 5.0117e-09 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 4.6576e-09 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 4.3432e-09 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 4.1347e-09 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.9170e-09 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.7744e-09 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.6271e-09 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.5122e-09 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.3770e-09 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.2755e-09 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.1442e-09 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 3.0436e-09 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.9376e-09 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.8466e-09 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.7910e-09 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.7195e-09 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.6652e-09 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.6431e-09 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.6177e-09 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.5888e-09 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.5621e-09 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.5515e-09 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "780/780 [==============================] - 3s 3ms/step - loss: 2.5234e-09 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "780/780 [==============================] - 3s 3ms/step - loss: 2.5076e-09 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "780/780 [==============================] - 2s 3ms/step - loss: 2.4898e-09 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.4606e-09 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.4455e-09 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.4185e-09 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.3945e-09 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.3781e-09 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.3657e-09 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.3446e-09 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.3264e-09 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.3140e-09 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.2944e-09 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.2777e-09 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.2666e-09 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.2525e-09 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.2329e-09 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.2233e-09 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.2073e-09 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.1871e-09 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.1748e-09 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.1634e-09 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.1501e-09 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.1335e-09 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.1199e-09 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.0991e-09 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.0922e-09 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.0780e-09 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.0585e-09 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.0453e-09 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.0307e-09 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 2.0115e-09 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.9988e-09 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.9854e-09 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.9709e-09 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.9581e-09 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "780/780 [==============================] - 2s 2ms/step - loss: 1.9486e-09 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2pzvOrgdx5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "25114d82-5ab0-4399-8b30-2146c269985a"
      },
      "source": [
        "##Resultado redes neuronales\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1437,   11],\n",
              "       [  11,  213]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88ZYPuxRe9yo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "05b827df-880f-4252-bc9a-be388639ceac"
      },
      "source": [
        "classifier.evaluate(X_test, y_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.17599910497665405, 0.9868420958518982]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0B1G6GngeKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Resultado regresion\n",
        "array([[1443,    5],\n",
        "       [  31,  193]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0N0Li84gjok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Los resultados son muy similares, conllevando más trabajo las redes neuronales."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}